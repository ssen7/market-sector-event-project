{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Dropout\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from time import time\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs/{}'.format(time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>distance</th>\n",
       "      <th>left_slope</th>\n",
       "      <th>right_slope</th>\n",
       "      <th>event_sector</th>\n",
       "      <th>target_sector</th>\n",
       "      <th>target_sector_average_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.878098</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.235240</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Financials</td>\n",
       "      <td>0.891598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047964</td>\n",
       "      <td>0.020885</td>\n",
       "      <td>0.998019</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Financials</td>\n",
       "      <td>0.891598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.661844</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.024434</td>\n",
       "      <td>0.028068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Financials</td>\n",
       "      <td>0.891598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491712</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.056109</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.996357</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Financials</td>\n",
       "      <td>0.901922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.502503</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.984032</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Financials</td>\n",
       "      <td>0.907147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     height     width  distance  left_slope  right_slope event_sector  \\\n",
       "0  0.878098  0.000661  0.000000    1.000000     0.235240  Health Care   \n",
       "1  1.000000  1.000000  0.047964    0.020885     0.998019  Health Care   \n",
       "2  0.661844  0.000051  0.024434    0.028068     0.000000  Health Care   \n",
       "3  0.491712  0.000272  0.056109    0.000154     0.996357  Health Care   \n",
       "4  0.502503  0.000013  0.013575    0.001461     0.984032  Health Care   \n",
       "\n",
       "  target_sector  target_sector_average_price  \n",
       "0    Financials                     0.891598  \n",
       "1    Financials                     0.891598  \n",
       "2    Financials                     0.891598  \n",
       "3    Financials                     0.901922  \n",
       "4    Financials                     0.907147  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/event_data_correct/Health Care.csv')\n",
    "data.name = 'Event_IT_Tar_Fin'\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>distance</th>\n",
       "      <th>left_slope</th>\n",
       "      <th>right_slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.878098</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.235240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047964</td>\n",
       "      <td>0.020885</td>\n",
       "      <td>0.998019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.661844</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.024434</td>\n",
       "      <td>0.028068</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491712</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.056109</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.996357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.502503</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.984032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     height     width  distance  left_slope  right_slope\n",
       "0  0.878098  0.000661  0.000000    1.000000     0.235240\n",
       "1  1.000000  1.000000  0.047964    0.020885     0.998019\n",
       "2  0.661844  0.000051  0.024434    0.028068     0.000000\n",
       "3  0.491712  0.000272  0.056109    0.000154     0.996357\n",
       "4  0.502503  0.000013  0.013575    0.001461     0.984032"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:, :5]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.891598\n",
       "1    0.891598\n",
       "2    0.891598\n",
       "3    0.901922\n",
       "4    0.907147\n",
       "Name: target_sector_average_price, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.iloc[:, -1]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "\n",
    "We reshape the data for 1D convolution, with 5 features. We have variable **image_height**, which indicates the height of the convolution window. The default image height is 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshapes data into n (len(data)/image_height) image_heightx5 data values.\n",
    "def split_reshape_dataset(X, y, image_height=5):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    \n",
    "    X_train = make_dataset_whole(X_train,image_height)\n",
    "    X_test = make_dataset_whole(X_test,image_height)\n",
    "    y_train = make_dataset_whole(y_train,image_height)\n",
    "    y_test = make_dataset_whole(y_test,image_height)\n",
    "    \n",
    "    X_train = np.reshape(X_train.values, (-1, image_height, 5))\n",
    "    X_test = np.reshape(X_test.values, (-1, image_height, 5))\n",
    "    y_train = np.reshape(y_train.values, (-1, image_height))\n",
    "    y_test = np.reshape(y_test.values, (-1, image_height))\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# to make sure we have uniform sized images. \n",
    "# eg. If there are 161 rows of observations and we want to make predictions on 5 time steps each,\n",
    "# this will reduce the dataset to 160 observations as 160%5==0\n",
    "def make_dataset_whole(X, image_height=5):\n",
    "    X = X.reset_index(drop='index')\n",
    "    x_shape=X.shape[0]\n",
    "    i = x_shape%image_height\n",
    "    if i != 0:\n",
    "        X = X.drop(list(range(x_shape-1, x_shape-i-1,-1)),axis=0)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53, 5), (53, 5, 5))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = split_reshape_dataset(X,y)\n",
    "\n",
    "y_train.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('../data/event_data_correct/Health Care.csv')\n",
    "data2 = data1[data1['target_sector']=='Financials']\n",
    "data1 = data1[data1['target_sector']=='Information Technology']\n",
    "data1.name = 'HC_IT'\n",
    "data2.name = 'HC_Fin'\n",
    "\n",
    "data3 = pd.read_csv('../data/event_data_correct/Financials.csv')\n",
    "data4 = data3[data3['target_sector']=='Health Care']\n",
    "data3 = data3[data3['target_sector']=='Information Technology']\n",
    "data3.name = 'Fin_IT'\n",
    "data4.name = 'Fin_HC'\n",
    "\n",
    "data5 = pd.read_csv('../data/event_data_correct/Information Technology.csv')\n",
    "data6 = data5[data5['target_sector']=='Health Care']\n",
    "data5 = data5[data5['target_sector']=='Financials']\n",
    "data5.name = 'IT_Fin'\n",
    "data6.name = 'IT_HC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build basic model using 1 1D convolution layer with kernel_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(X_train, y_train):\n",
    "    verbose, epochs, batch_size = 0, 20, 4\n",
    "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=16, kernel_size=2, activation='relu',\n",
    "                     input_shape=(n_timesteps, n_features)))\n",
    "    \n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(n_outputs))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.fit(X_train, y_train, epochs=epochs,\n",
    "              batch_size=batch_size, verbose=verbose)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0710264988748992\n",
      "0.1038760449679248\n",
      "0.052586026925635854\n",
      "0.08694150199921725\n",
      "0.07360786023357886\n",
      "0.07052792366133113\n",
      "{'HC_IT': 0.0710264988748992, 'HC_Fin': 0.1038760449679248, 'Fin_IT': 0.052586026925635854, 'Fin_HC': 0.08694150199921725, 'IT_Fin': 0.07360786023357886, 'IT_HC': 0.07052792366133113}\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "datalist = [data1, data2, data3, data4, data5, data6]\n",
    "index = []\n",
    "cols = []\n",
    "mse_dict = {}\n",
    "while i < len(datalist):\n",
    "    data = datalist[i]\n",
    "    name = data.name\n",
    "    event_sector = name.split('_')[0]\n",
    "    target_sector = name.split('_')[1]\n",
    "    index+=[event_sector]\n",
    "    cols+=[target_sector]\n",
    "    X = data.iloc[:, :5]\n",
    "    y = data.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = split_reshape_dataset(X,y)\n",
    "    model = build_model(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_dict[name] = mse\n",
    "    print(mse)\n",
    "    i+=1\n",
    "print(mse_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07642764277709785"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(mse_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with 2 convolution layers with kernel_size=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_2(X_train, y_train):\n",
    "    verbose, epochs, batch_size = 0, 20, 4\n",
    "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=10, kernel_size=2, activation='relu',\n",
    "                     input_shape=(n_timesteps, n_features)))\n",
    "    model.add(Conv1D(filters=20, kernel_size=2, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # fit network\n",
    "    model.fit(X_train, y_train, epochs=epochs,\n",
    "              batch_size=batch_size, verbose=verbose)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0617984304117845\n",
      "0.09955359472406052\n",
      "0.04983835030783752\n",
      "0.07947932381960388\n",
      "0.0746830333119998\n",
      "0.065484104795866\n",
      "{'HC_IT': 0.0617984304117845, 'HC_Fin': 0.09955359472406052, 'Fin_IT': 0.04983835030783752, 'Fin_HC': 0.07947932381960388, 'IT_Fin': 0.0746830333119998, 'IT_HC': 0.065484104795866}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0718061395618587"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "datalist = [data1, data2, data3, data4, data5, data6]\n",
    "index = []\n",
    "cols = []\n",
    "mse_dict = {}\n",
    "while i < len(datalist):\n",
    "    data = datalist[i]\n",
    "    name = data.name\n",
    "    event_sector = name.split('_')[0]\n",
    "    target_sector = name.split('_')[1]\n",
    "    index+=[event_sector]\n",
    "    cols+=[target_sector]\n",
    "    X = data.iloc[:, :5]\n",
    "    y = data.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = split_reshape_dataset(X,y)\n",
    "    model = build_model_2(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_dict[name] = mse\n",
    "    print(mse)\n",
    "    i+=1\n",
    "print(mse_dict)\n",
    "np.mean(list(mse_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the timestep size from 5 to 10 and building model with 3 convolution layers.\n",
    "\n",
    "## Increasing the timestep allows us to use more convolution layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_3(X_train, y_train):\n",
    "    verbose, epochs, batch_size = 0, 20, 4\n",
    "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=10, kernel_size=3, activation='relu',\n",
    "                     input_shape=(n_timesteps, n_features)))\n",
    "    model.add(Conv1D(filters=20, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(filters=20, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # fit network\n",
    "    model.fit(X_train, y_train, epochs=epochs,\n",
    "              batch_size=batch_size, verbose=verbose, callbacks=[tensorboard])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the changed timestep size with build_model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06569834809635004\n",
      "0.11010965933484385\n",
      "0.058017275804901444\n",
      "0.06905296256537138\n",
      "0.07760514158866483\n",
      "0.08134900951710501\n",
      "{'HC_IT': 0.06569834809635004, 'HC_Fin': 0.11010965933484385, 'Fin_IT': 0.058017275804901444, 'Fin_HC': 0.06905296256537138, 'IT_Fin': 0.07760514158866483, 'IT_HC': 0.08134900951710501}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0769720661512061"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "datalist = [data1, data2, data3, data4, data5, data6]\n",
    "index = []\n",
    "cols = []\n",
    "mse_dict = {}\n",
    "while i < len(datalist):\n",
    "    data = datalist[i]\n",
    "    name = data.name\n",
    "    event_sector = name.split('_')[0]\n",
    "    target_sector = name.split('_')[1]\n",
    "    index+=[event_sector]\n",
    "    cols+=[target_sector]\n",
    "    X = data.iloc[:, :5]\n",
    "    y = data.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = split_reshape_dataset(X,y, image_height=10) ## change image height\n",
    "    model = build_model_2(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_dict[name] = mse\n",
    "    print(mse)\n",
    "    i+=1\n",
    "print(mse_dict)\n",
    "np.mean(list(mse_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07033391227569288\n",
      "0.1147533654140783\n",
      "0.057575479504362356\n",
      "0.06702934727546803\n",
      "0.08236966686271668\n",
      "0.07691662976232136\n",
      "{'HC_IT': 0.07033391227569288, 'HC_Fin': 0.1147533654140783, 'Fin_IT': 0.057575479504362356, 'Fin_HC': 0.06702934727546803, 'IT_Fin': 0.08236966686271668, 'IT_HC': 0.07691662976232136}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07816306684910661"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Final CNN\n",
    "## Testing with build_model_3\n",
    "i = 0\n",
    "datalist = [data1, data2, data3, data4, data5, data6]\n",
    "index = []\n",
    "cols = []\n",
    "mse_dict = {}\n",
    "while i < len(datalist):\n",
    "    data = datalist[i]\n",
    "    name = data.name\n",
    "    event_sector = name.split('_')[0]\n",
    "    target_sector = name.split('_')[1]\n",
    "    index+=[event_sector]\n",
    "    cols+=[target_sector]\n",
    "    X = data.iloc[:, :5]\n",
    "    y = data.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = split_reshape_dataset(X,y, image_height=10) ## change image height\n",
    "    model = build_model_3(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_dict[name] = mse\n",
    "    print(mse)\n",
    "    i+=1\n",
    "print(mse_dict)\n",
    "np.mean(list(mse_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Stochastic Gradient Descent optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_4(X_train, y_train):\n",
    "    verbose, epochs, batch_size = 0, 20, 4\n",
    "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=10, kernel_size=3, activation='relu',\n",
    "                     input_shape=(n_timesteps, n_features)))\n",
    "    model.add(Conv1D(filters=20, kernel_size=3, activation='relu'))\n",
    "    model.add(Conv1D(filters=20, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs))\n",
    "    model.compile(loss='mse', optimizer='sgd')\n",
    "    # fit network\n",
    "    model.fit(X_train, y_train, epochs=epochs,\n",
    "              batch_size=batch_size, verbose=verbose)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13289399564057355\n",
      "0.13858938596234252\n",
      "0.0811121078809812\n",
      "0.1220483513056743\n",
      "0.08281941292868725\n",
      "0.0743933197246958\n",
      "{'HC_IT': 0.13289399564057355, 'HC_Fin': 0.13858938596234252, 'Fin_IT': 0.0811121078809812, 'Fin_HC': 0.1220483513056743, 'IT_Fin': 0.08281941292868725, 'IT_HC': 0.0743933197246958}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10530942890715911"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Testing with sgd\n",
    "i = 0\n",
    "datalist = [data1, data2, data3, data4, data5, data6]\n",
    "index = []\n",
    "cols = []\n",
    "mse_dict = {}\n",
    "while i < len(datalist):\n",
    "    data = datalist[i]\n",
    "    name = data.name\n",
    "    event_sector = name.split('_')[0]\n",
    "    target_sector = name.split('_')[1]\n",
    "    index+=[event_sector]\n",
    "    cols+=[target_sector]\n",
    "    X = data.iloc[:, :5]\n",
    "    y = data.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = split_reshape_dataset(X,y, image_height=10) ## change image height\n",
    "    model = build_model_4(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_dict[name] = mse\n",
    "    print(mse)\n",
    "    i+=1\n",
    "print(mse_dict)\n",
    "np.mean(list(mse_dict.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
